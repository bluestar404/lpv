{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7e0e2d-81e9-4598-a96b-46a02ab71d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "from tensorflow.keras.models import Sequential  # Sequential model: a linear stack of layers in Keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input  # Dense (fully connected layer), Dropout (regularization layer), and Input layer\n",
    "from tensorflow.keras.optimizers import RMSprop  # RMSprop optimizer: used for training the model with adaptive learning rates\n",
    "from tensorflow.keras.datasets import mnist  # MNIST dataset: a famous dataset of handwritten digits (0-9)\n",
    "import matplotlib.pyplot as plt  # Matplotlib: used for plotting graphs and visualizations\n",
    "import numpy as np  # NumPy: a library for numerical computing, particularly for arrays and matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37febece-cde0-4b01-8e26-97a688b5d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the OCR dataset (MNIST)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# 'x_train' contains the training images (28x28 pixel images of handwritten digits)\n",
    "# 'y_train' contains the labels for the training images (digits 0-9)\n",
    "# 'x_test' contains the test images (28x28 pixel images of handwritten digits, unseen during training)\n",
    "# 'y_test' contains the labels for the test images (digits 0-9 for evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a43fea0b-8524-4eb8-b8ed-5e219ed68d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape the flattened image back to 28x28\n",
    "image = x_train[0].reshape(28, 28)  # Reshaping the first training image (which is a 1D array of 784 values) back to a 28x28 2D array\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image, cmap='grey')  # Displaying the image using Matplotlib. 'cmap' sets the color map to grayscale\n",
    "plt.show()  # Show the image plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e57d787-a8f3-42ab-8709-d1650c884e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to fit the model\n",
    "x_train = x_train.reshape(60000, 784)  # Reshaping the training data from (60000, 28, 28) to (60000, 784)\n",
    "# x_train originally has 60000 images, each 28x28 pixels, so we flatten each image to a 1D array of 784 pixels\n",
    "\n",
    "x_test = x_test.reshape(10000, 784) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c74ff21-ff42-4eda-bcbe-46d0f3d0d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "num_classes = 10  # Define the number of classes (for MNIST, there are 10 classes: digits 0-9)\n",
    "\n",
    "# Convert the labels into binary class matrices (one-hot encoding)\n",
    "y_train = np.eye(num_classes)[y_train]  # For each label in y_train, create a binary vector where the position of the digit is 1, and others are 0\n",
    "y_test = np.eye(num_classes)[y_test]    # Similarly, convert y_test labels to one-hot encoded binary vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42df6270-bb7c-43b7-a0f4-155264668508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()  # Initialize a sequential model, which means layers are stacked one after the other\n",
    "\n",
    "model.add(Input(shape=(784,)))  # Define the input layer with 784 units (for each pixel in the 28x28 MNIST images)\n",
    "# The input shape is (784,) because each image has been flattened into a 1D array of 784 pixels\n",
    "\n",
    "model.add(Dense(512, activation='relu'))  # Add a dense layer with 512 neurons and ReLU activation function\n",
    "# Dense layer is a fully connected layer, meaning each neuron in this layer is connected to all the neurons in the previous layer\n",
    "\n",
    "model.add(Dropout(0.2))  # Add a dropout layer to prevent overfitting. 20% of the neurons will be randomly turned off during training\n",
    "\n",
    "model.add(Dense(512, activation='relu'))  # Add another dense layer with 512 neurons and ReLU activation\n",
    "\n",
    "model.add(Dropout(0.2))  # Add another dropout layer with 20% dropout rate\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Add the output layer with 'num_classes' neurons (10 for MNIST)\n",
    "# 'softmax' activation is used for multi-class classification, where it converts raw output values (logits) into probabilities\n",
    "# Each output neuron represents the probability of the input belonging to a specific class (0-9 for MNIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7564864-35cc-45f2-b727-e34ae021fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',  # Define the loss function. 'categorical_crossentropy' is used for multi-class classification.\n",
    "              optimizer=RMSprop(),  # Use the RMSprop optimizer, which is well-suited for training deep neural networks.\n",
    "              metrics=['accuracy'])  # Track accuracy during training as an evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e81fef-c6d5-4510-843f-f76eefd2c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7950 - loss: 13.4677 - val_accuracy: 0.9281 - val_loss: 0.3259\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8991 - loss: 0.5688 - val_accuracy: 0.9384 - val_loss: 0.2451\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9186 - loss: 0.4229 - val_accuracy: 0.9372 - val_loss: 0.2810\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9325 - loss: 0.3449 - val_accuracy: 0.9594 - val_loss: 0.1796\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9390 - loss: 0.3225 - val_accuracy: 0.9477 - val_loss: 0.2762\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa451362-e1d9-48b6-972b-ea7639a2db88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.27623456716537476\n",
      "Test accuracy: 0.947700023651123\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)  # Evaluate the trained model on the test data (x_test and y_test)\n",
    "# The 'evaluate' function computes the loss and any metrics defined during compilation (in this case, accuracy)\n",
    "\n",
    "print('Test loss:', score[0])  # The first element of 'score' is the test loss\n",
    "print('Test accuracy:', score[1])  # The second element of 'score' is the test accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444fa95-562b-412b-9f1c-5e11c07bc8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
