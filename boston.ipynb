{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d628b18e-a52f-427e-98f2-a411f79a54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Linear regression by using Deep Neural network: Implement Boston housing\n",
    "#  price.prediction problem by Linear regression using Deep Neural network. Use Boston House price\n",
    "#  prediction dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4796b3-9763-45a9-bbf0-049563f1adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np  # For numerical operations, mainly array manipulations\n",
    "from sklearn.model_selection import train_test_split  # Function to split data into training and test sets\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  # Metrics to evaluate model performance\n",
    "from sklearn.linear_model import LinearRegression  # Linear regression model from Scikit-learn\n",
    "from keras.models import Sequential  # Keras Sequential model for building neural networks\n",
    "from keras.layers import Dense, Input  # Layers for creating neural network architecture\n",
    "from keras.datasets import boston_housing  # Boston housing dataset (a popular regression dataset)\n",
    "\n",
    "# Mean Squared Error (MSE): A metric that measures the average squared difference between the actual and predicted values.\n",
    "# It gives a sense of how far off predictions are from the real values. Smaller MSE indicates better performance.\n",
    "# Formula: MSE = (1/n) * Σ(actual - predicted)^2\n",
    "\n",
    "# Mean Absolute Error (MAE): A metric that measures the average of the absolute differences between actual and predicted values.\n",
    "# Unlike MSE, MAE doesn't square the differences, making it less sensitive to large outliers. It's a more intuitive measure.\n",
    "# Formula: MAE = (1/n) * Σ|actual - predicted|\n",
    "\n",
    "# R-squared (R²): This is a statistical measure of how well the regression predictions approximate the real data points.\n",
    "# R² ranges from 0 to 1. A value of 1 means the model perfectly fits the data, while a value closer to 0 means the model is poor.\n",
    "# Formula: R² = 1 - (Σ(actual - predicted)² / Σ(actual - mean(actual))²)\n",
    "# It can also be interpreted as the proportion of variance in the dependent variable that is predictable from the independent variables.\n",
    "\n",
    "# The Boston Housing dataset contains data on different features (e.g., crime rate, number of rooms) and the price of homes in Boston.\n",
    "# It is often used as a benchmark for testing regression models, as the target variable (housing price) is continuous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6bf88da-f164-4c4e-9f4e-c5a465beb56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Boston Housing data using Keras\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbec41d-e477-4f9f-8cd2-43fe3fac94ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91a8bf27-c188-471b-a10a-3d29fc3faa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "mean, std = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012a115a-5ea6-403b-99a8-8a27e5d4acfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR RMSE: 4.8161809825237025\n",
      "LR R2: 0.7213535934621552\n",
      "LR MAE: 3.4641858124067166\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model\n",
    "# Step 1: Initialize and train the Linear Regression model using the training data (X_train, y_train)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "# The model is being fitted (trained) on the data, where:\n",
    "# - X_train is the training data containing the features.\n",
    "# - y_train is the target variable (the actual values we want to predict).\n",
    "# After calling .fit(), the model learns the relationships between the features and target variable.\n",
    "\n",
    "# Step 2: Make predictions using the trained model on the test data (X_test)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "# .predict() generates the model's predicted values (y_pred_lr) for the test data (X_test).\n",
    "# X_test contains the features for the test set, and y_pred_lr will contain the predicted target values.\n",
    "\n",
    "# Step 3: Calculate and print the Root Mean Squared Error (RMSE) to evaluate model performance\n",
    "print(\"LR RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lr)))\n",
    "# mean_squared_error(y_test, y_pred_lr) calculates the Mean Squared Error (MSE), \n",
    "# which is the average of the squared differences between the true values (y_test) and predicted values (y_pred_lr).\n",
    "# np.sqrt() then takes the square root of the MSE to return the RMSE, which is in the same units as the target variable.\n",
    "# RMSE gives an idea of how much error the model is making in predicting the target.\n",
    "\n",
    "# Step 4: Calculate and print the R-squared (R²) score to evaluate model fit\n",
    "print(\"LR R2:\", r2_score(y_test, y_pred_lr))\n",
    "# r2_score(y_test, y_pred_lr) calculates the R-squared score, which tells us the proportion of the variance in the target variable \n",
    "# that is explained by the features (input variables).\n",
    "# A higher R² (close to 1) indicates that the model explains most of the variance, while a lower R² (close to 0) means the model doesn't explain much.\n",
    "\n",
    "# Step 5: Calculate and print the Mean Absolute Error (MAE) to evaluate model performance\n",
    "print(\"LR MAE:\", mean_absolute_error(y_test, y_pred_lr))\n",
    "# mean_absolute_error(y_test, y_pred_lr) calculates the Mean Absolute Error (MAE), which is the average of the absolute differences \n",
    "# between the true values (y_test) and predicted values (y_pred_lr).\n",
    "# MAE is a simple metric that gives a sense of the average magnitude of the prediction errors without considering direction.\n",
    "# It is less sensitive to large errors compared to RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95180289-a799-452c-98df-58ccb65a92f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2457a547790>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deep Neural Network Model\n",
    "model = Sequential([  # Initialize a Sequential model to build the neural network layer by layer\n",
    "    Input(shape=(13,)),  # Define the input layer with 13 features (input shape is 13 for the 13 input features in the dataset)\n",
    "    \n",
    "    Dense(128, activation='relu'),  # First hidden layer with 128 neurons and ReLU activation function\n",
    "    # The ReLU activation introduces non-linearity, allowing the network to learn more complex patterns\n",
    "    \n",
    "    Dense(64, activation='relu'),  # Second hidden layer with 64 neurons and ReLU activation\n",
    "    # The number of neurons can be reduced in subsequent layers to help the network generalize better\n",
    "    \n",
    "    Dense(32, activation='relu'),  # Third hidden layer with 32 neurons and ReLU activation\n",
    "    \n",
    "    Dense(16, activation='relu'),  # Fourth hidden layer with 16 neurons and ReLU activation\n",
    "    \n",
    "    Dense(1)  # Output layer with 1 neuron (since we're predicting a single continuous value, no activation function is used here)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])  \n",
    "# Compile the model using the Adam optimizer, Mean Squared Error (MSE) as the loss function (since it's a regression problem),\n",
    "# and Mean Absolute Error (MAE) as a metric to monitor during training.\n",
    "# - Adam optimizer is a popular optimization algorithm.\n",
    "# - MSE is a common loss function for regression tasks, aiming to minimize the squared difference between predicted and actual values.\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.05, verbose=0)  \n",
    "# Train the model on the training data (X_train, y_train) for 100 epochs\n",
    "# - validation_split=0.05 means 5% of the training data will be used for validation during training\n",
    "# - verbose=0 suppresses the output of training progress (set verbose=1 or 2 if you want more information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464f49f8-edeb-49f1-ac7e-0984ae90ba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN MSE: 15.915617942810059\n",
      "DNN MAE: 2.4936814308166504\n"
     ]
    }
   ],
   "source": [
    "# DNN Evaluation\n",
    "mse, mae = model.evaluate(X_test, y_test, verbose=0)  # Evaluate the model on the test data, return MSE and MAE\n",
    "\n",
    "# MSE: Mean Squared Error - Measures the average of the squared differences between actual and predicted values.\n",
    "# It penalizes larger errors more due to squaring.\n",
    "\n",
    "print(\"DNN MSE:\", mse)\n",
    "\n",
    "# MAE: Mean Absolute Error - Measures the average of the absolute differences between actual and predicted values.\n",
    "# It gives a simple idea of how much error the model is making, and is less sensitive to outliers than MSE.\n",
    "print(\"DNN MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26130e26-4402-42f7-92b9-cef386c2d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price: 17.136747\n"
     ]
    }
   ],
   "source": [
    "# New prediction\n",
    "new_sample = [[0.1, 10.0, 5.0, 0, 0.4, 6.0, 50, 6.0, 1, 400, 20, 300, 10]]\n",
    "new_sample_scaled = (np.array(new_sample) - mean) / std\n",
    "pred = model.predict(new_sample_scaled, verbose=0)\n",
    "print(\"Predicted price:\", pred[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
